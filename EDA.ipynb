{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZuBj4KyFC06RRijuZF4Xq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chuy-zip/PROYECTO2_DS/blob/main/EDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJoD3mOXw4uw",
        "outputId": "2f1aefb8-a281-4562-cdc9-d0d372dd8fe5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PROYECTO2_DS'...\n",
            "remote: Enumerating objects: 4214, done.\u001b[K\n",
            "remote: Counting objects: 100% (4214/4214), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4207/4207), done.\u001b[K\n",
            "remote: Total 4214 (delta 4), reused 4210 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (4214/4214), 9.87 MiB | 10.56 MiB/s, done.\n",
            "Resolving deltas: 100% (4/4), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/chuy-zip/PROYECTO2_DS.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords as nltk_stop\n",
        "from nltk.util import ngrams\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from textblob import TextBlob\n",
        "import requests"
      ],
      "metadata": {
        "id": "QzLQ347rxGVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"PROYECTO2_DS/data/train_clean.csv\")"
      ],
      "metadata": {
        "id": "lFwSzy7xxSrJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}